# ğŸ¤– Smart RAG Chatbot with Ollama

**Tamamen Ã¼cretsiz, local olarak Ã§alÄ±ÅŸan, akÄ±llÄ± bir RAG (Retrieval-Augmented Generation) chatbot sistemi.**

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![LangChain](https://img.shields.io/badge/LangChain-0.2.7-green.svg)](https://langchain.com)
[![Ollama](https://img.shields.io/badge/Ollama-Llama%203.1-orange.svg)](https://ollama.com)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## âœ¨ Ã–zellikler

### ğŸ¯ Temel Ã–zellikler
- **ğŸ†“ Tamamen Ãœcretsiz**: Local LLM (Ollama) kullanÄ±r, API maliyeti $0
- **ğŸ§  AkÄ±llÄ± Routing**: Sohbet vs bilgi sorularÄ±nÄ± otomatik ayÄ±rÄ±r
- **ğŸ“š RAG Sistemi**: Kendi dÃ¶kÃ¼manlarÄ±nÄ±zdan bilgi Ã¶ÄŸrenir
- **ğŸ’¬ Sohbet HafÄ±zasÄ±**: Son 10 mesajÄ± hatÄ±rlar, context-aware cevaplar verir
- **ğŸ” Kaynak GÃ¶sterimi**: Hangi dÃ¶kÃ¼manlardan bilgi aldÄ±ÄŸÄ±nÄ± gÃ¶sterir
- **ğŸŒ Hibrid Mode**: DÃ¶kÃ¼manlarda bilgi yoksa LLM'in kendi bilgisiyle cevaplar

### ğŸ›¡ï¸ Profesyonel Ã–zellikler
- **Structured Logging**: JSON formatÄ±nda detaylÄ± loglar
- **Error Handling**: Comprehensive exception handling
- **Input Validation**: GÃ¼venlik odaklÄ± input validasyonu
- **Retry Mechanism**: Exponential backoff ile otomatik retry
- **Circuit Breaker**: Tekrarlayan hatalardan korunma
- **Caching**: In-memory cache ile performans optimizasyonu
- **Metrics**: Real-time performans metrikleri

---

## ğŸ¬ Demo

### Sohbet Modu
```
Sen: Merhaba, nasÄ±lsÄ±n?
ğŸ¤–: Merhaba! Ä°yiyim, teÅŸekkÃ¼rler. Size nasÄ±l yardÄ±mcÄ± olabilirim?

Sen: Ne yapÄ±yorsun?
ğŸ¤–: Sizinle sohbet ediyorum! SorularÄ±nÄ±zÄ± yanÄ±tlamaya hazÄ±rÄ±m.
```

### Bilgi Modu (DÃ¶kÃ¼manlardan)
```
Sen: What is agent memory?
ğŸ¤–: Agent memory, LLM-based autonomous ajanlarÄ±n geÃ§miÅŸ 
    etkileÅŸimleri ve bilgileri saklama yeteneÄŸidir...
ğŸ“š Kaynak: 4 dÃ¶kÃ¼man
   Dosyalar: 2023-06-23-agent.md
```

### Hibrid Mod (LLM Bilgisi)
```
Sen: Python nedir?
ğŸ¤–: Python, yÃ¼ksek seviye, yorumlamalÄ± bir programlama dilidir...
ğŸ§  (Kendi bilgimle cevapladÄ±m)
```

### Context-Aware (HafÄ±za)
```
Sen: What is agent memory?
ğŸ¤–: [detaylÄ± cevap]

Sen: Peki bu nasÄ±l Ã§alÄ±ÅŸÄ±r?  â† Ã–nceki soruyu hatÄ±rlÄ±yor!
ğŸ¤–: Agent memory'nin Ã§alÄ±ÅŸma prensibi...
```

---

## ğŸ“¦ Kurulum

### Gereksinimler
- Python 3.10+
- 8GB+ RAM (16GB Ã¶nerilir)
- Windows/Linux/Mac

### 1ï¸âƒ£ Repository'yi KlonlayÄ±n
```bash
git clone https://github.com/nurullahsahinn/HybridRAG.git
cd HybridRAG
```

### 2ï¸âƒ£ Python BaÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± YÃ¼kleyin
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Ollama'yÄ± Kurun

**Windows:**
```bash
# Ä°ndir: https://ollama.com/download/windows
# Kur ve ardÄ±ndan:
ollama pull llama3.1:8b
ollama pull nomic-embed-text
```

**Linux/Mac:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
ollama pull llama3.1:8b
ollama pull nomic-embed-text
```

### 4ï¸âƒ£ KonfigÃ¼rasyonu AyarlayÄ±n

`.env` dosyasÄ± oluÅŸturun:
```bash
LLM_PROVIDER=ollama
EMBEDDING_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b
EMBEDDING_MODEL=nomic-embed-text

CHROMA_PERSIST_DIRECTORY=./.chroma
CHROMA_COLLECTION_NAME=rag-chroma
CHUNK_SIZE=250
CHUNK_OVERLAP=50
RETRIEVAL_K=4

LOG_LEVEL=INFO
LOG_FORMAT=console
```

### 5ï¸âƒ£ DÃ¶kÃ¼manlarÄ± YÃ¼kleyin (Ä°steÄŸe BaÄŸlÄ±)

Sistem default olarak AI/ML hakkÄ±nda 3 web sayfasÄ± yÃ¼kler. Kendi dÃ¶kÃ¼manlarÄ±nÄ±zÄ± eklemek iÃ§in:

```bash
python load_custom_docs.py path/to/your/documents/
```

Desteklenen formatlar: PDF, TXT, DOCX

---

## ğŸš€ KullanÄ±m

### Ä°nteraktif Mod (Ã–nerilen)
```bash
python cli.py
```

SÃ¼rekli soru sorabileceÄŸiniz interactive bir chat baÅŸlatÄ±r.

### Programatik KullanÄ±m
```python
from main import ask_question_smart

result = ask_question_smart("What is machine learning?")

print(result['answer'])
print(f"DÃ¶kÃ¼man kullanÄ±ldÄ±: {result['used_documents']}")
print(f"Kaynak: {result['sources']}")
```

### Kendi DÃ¶kÃ¼manlarÄ±nÄ±zÄ± YÃ¼kleyin
```bash
# PDF klasÃ¶rÃ¼nÃ¼zÃ¼ gÃ¶sterin
python load_custom_docs.py "C:/MyDocuments/AI/"

# ArdÄ±ndan cli'yi baÅŸlatÄ±n
python cli.py
```

---

## ğŸ“ Proje YapÄ±sÄ±

```
smart-rag-chatbot/
â”œâ”€â”€ main.py                    # Ana RAG engine (smart routing, memory)
â”œâ”€â”€ cli.py                     # Interactive CLI
â”œâ”€â”€ config.py                  # Configuration management
â”œâ”€â”€ exceptions.py              # Custom exceptions
â”œâ”€â”€ llm_provider.py            # LLM abstraction (OpenAI/Ollama)
â”œâ”€â”€ ingestion.py               # Document processing & vectorstore
â”œâ”€â”€ load_custom_docs.py        # Custom document loader
â”‚
â”œâ”€â”€ utils/                     # Utility modules
â”‚   â”œâ”€â”€ cache.py              # Caching mechanism
â”‚   â”œâ”€â”€ logger.py             # Structured logging
â”‚   â”œâ”€â”€ metrics.py            # Performance metrics
â”‚   â”œâ”€â”€ retry.py              # Retry & circuit breaker
â”‚   â””â”€â”€ validation.py         # Input validation
â”‚
â”œâ”€â”€ tests/                     # Unit tests
â”‚   â”œâ”€â”€ test_cache.py
â”‚   â”œâ”€â”€ test_config.py
â”‚   â”œâ”€â”€ test_metrics.py
â”‚   â”œâ”€â”€ test_retry.py
â”‚   â””â”€â”€ test_validation.py
â”‚
â”œâ”€â”€ docs/                      # Documentation
â”‚   â”œâ”€â”€ QUICK_START.md        # Quick start guide
â”‚   â””â”€â”€ setup_ollama.md       # Ollama setup guide
â”‚
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .env.example              # Example environment config
â””â”€â”€ README.md                 # This file
```

---

## ğŸ”§ KonfigÃ¼rasyon

### LLM Provider SeÃ§imi

**Ollama (Local - Ãœcretsiz):**
```env
LLM_PROVIDER=ollama
OLLAMA_MODEL=llama3.1:8b
```

**OpenAI (Cloud - Ãœcretli):**
```env
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your_key_here
OPENAI_MODEL=gpt-4o-mini
```

### Embedding Provider

**Ollama (YavaÅŸ ama Ã¼cretsiz):**
```env
EMBEDDING_PROVIDER=ollama
EMBEDDING_MODEL=nomic-embed-text
```

**OpenAI (HÄ±zlÄ±, ~$0.01/1000 dÃ¶kÃ¼man):**
```env
EMBEDDING_PROVIDER=openai
OPENAI_API_KEY=sk-your_key_here
```

**ğŸ’¡ Tavsiye:** Embedding iÃ§in OpenAI, LLM iÃ§in Ollama kullanÄ±n!

---

## ğŸ¯ KullanÄ±m SenaryolarÄ±

### ğŸ“š Ders Ã‡alÄ±ÅŸma AsistanÄ±
```bash
# Ders notlarÄ±nÄ±zÄ± yÃ¼kleyin
python load_custom_docs.py "~/University/CS101/"

# Sorular sorun
python cli.py
> "Explain recursion with examples"
```

### ğŸ“– DokÃ¼mantasyon AsistanÄ±
```bash
# Proje dokÃ¼mantasyonunu yÃ¼kleyin
python load_custom_docs.py "./project-docs/"

# API kullanÄ±mÄ± hakkÄ±nda sorun
python cli.py
> "How do I authenticate with the API?"
```

### ğŸ§  KiÅŸisel Bilgi TabanÄ±
```bash
# NotlarÄ±nÄ±zÄ±, makalelerinizi yÃ¼kleyin
python load_custom_docs.py "~/Documents/Notes/"

# Ä°stediÄŸiniz zaman arayÄ±n
python cli.py
> "What did I learn about neural networks?"
```

---

## ğŸ“Š Performans

### Sistem Gereksinimleri

| BileÅŸen | Minimum | Ã–nerilen | Optimal |
|---------|---------|----------|---------|
| **RAM** | 8GB | 16GB | 32GB+ |
| **CPU** | i5 | i7 | Ryzen 9 |
| **GPU** | - | GTX 1660 Ti | RTX 3070+ |
| **Disk** | 10GB | 20GB | 50GB+ |

### HÄ±z KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Ä°ÅŸlem | CPU Only | With GPU | OpenAI API |
|-------|----------|----------|------------|
| **Soru-Cevap** | 30-60s | 3-8s | 2-3s |
| **Embedding (100 dÃ¶kÃ¼man)** | 5-10 min | 2-3 min | 10-30s |
| **Ä°lk Model YÃ¼kleme** | 20-30s | 5-10s | - |

### Maliyet KarÅŸÄ±laÅŸtÄ±rmasÄ±

| SeÃ§enek | Setup | AylÄ±k | Notlar |
|---------|-------|-------|--------|
| **Full Ollama** | $0 | $0 | YavaÅŸ embedding |
| **Ollama + OpenAI Embedding** | $0.01 | $0 | âœ… **Ã–nerilen** |
| **Full OpenAI** | $0 | $30-100 | En hÄ±zlÄ± |

---

## ğŸ§ª Testler

```bash
# TÃ¼m testleri Ã§alÄ±ÅŸtÄ±r
pytest

# Coverage raporu ile
pytest --cov=. --cov-report=html

# Belirli testler
pytest tests/test_validation.py -v
```

---

## ğŸ› Sorun Giderme

### "Ollama is not running"
```bash
# Windows: Start menÃ¼den Ollama uygulamasÄ±nÄ± baÅŸlat
# Linux/Mac:
ollama serve
```

### "Model not found"
```bash
# Modelleri kontrol et
ollama list

# Ä°ndir
ollama pull llama3.1:8b
ollama pull nomic-embed-text
```

### "GPU kullanÄ±lmÄ±yor"
```bash
# GPU kontrolÃ¼
nvidia-smi

# CUDA kurulu mu?
# https://developer.nvidia.com/cuda-downloads
```

### "Ã‡ok yavaÅŸ cevap veriyor"
1. **GPU kullanÄ±n** (30-50x hÄ±zlanÄ±r)
2. **Embedding iÃ§in OpenAI** kullanÄ±n ($0.01, 40x hÄ±zlÄ±)
3. **Daha kÃ¼Ã§Ã¼k model** kullanÄ±n: `llama3.2:3b`

---

## ğŸš§ Gelecek GeliÅŸtirmeler

- [ ] Web UI (Gradio/Streamlit)
- [ ] Multi-user support
- [ ] Persistent chat history (database)
- [ ] File upload via web interface
- [ ] Multi-language support
- [ ] Voice interface
- [ ] Mobile app
- [ ] Docker deployment
- [ ] API endpoints (FastAPI)
- [ ] Streaming responses

---

## ğŸ¤ KatkÄ±da Bulunma

KatkÄ±lar memnuniyetle karÅŸÄ±lanÄ±r! Ä°ÅŸte nasÄ±l katkÄ±da bulunabilirsiniz:

1. Fork edin
2. Feature branch oluÅŸturun: `git checkout -b feature/amazing-feature`
3. Commit edin: `git commit -m 'Add amazing feature'`
4. Push edin: `git push origin feature/amazing-feature`
5. Pull Request aÃ§Ä±n

---

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±ndadÄ±r. Detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.

---

## ğŸ™ TeÅŸekkÃ¼rler

Bu proje ÅŸu harika teknolojileri kullanÄ±r:

- [LangChain](https://langchain.com) - LLM framework
- [Ollama](https://ollama.com) - Local LLM runtime
- [Chroma](https://www.trychroma.com/) - Vector database
- [Llama 3.1](https://ai.meta.com/llama/) - Meta'nÄ±n aÃ§Ä±k kaynak LLM'i

---

## ğŸ“ Ä°letiÅŸim

SorularÄ±nÄ±z veya Ã¶nerileriniz iÃ§in:
- GitHub Issues: [Create an issue](https://github.com/nurullahsahinn/HybridRAG/issues)
- Email: nurullahsahin0088@gmail.com

---


**Not:** Bu proje tamamen Ã¼cretsiz ve aÃ§Ä±k kaynaklÄ±dÄ±r. Kendi AI asistanÄ±nÄ±zÄ± oluÅŸturmak iÃ§in mÃ¼kemmel bir baÅŸlangÄ±Ã§ noktasÄ±dÄ±r!

**Made with â¤ï¸ and ğŸ¤– by Nurullah Sahin**
