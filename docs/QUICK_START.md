# âš¡ HÄ±zlÄ± BaÅŸlangÄ±Ã§ - Local LLM ile Advanced RAG

## ğŸ¯ Hedef
Projenizi OpenAI API yerine **tamamen Ã¼cretsiz** local LLM (Ollama) ile Ã§alÄ±ÅŸtÄ±rmak!

---

## ğŸ“‹ AdÄ±m AdÄ±m Rehber

### 1ï¸âƒ£ Ollama Kur (5 dakika)

#### Windows:
```bash
# Ä°ndir: https://ollama.com/download/windows
# Kur: OllamaSetup.exe dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±r

# Kontrol et:
ollama --version
```

### 2ï¸âƒ£ Model Ä°ndir (10 dakika)

```bash
# Ana model (TÃ¼rkÃ§e desteÄŸi harika!)
ollama pull llama3.1:8b

# Embedding model (Ã¶nemli!)
ollama pull nomic-embed-text

# Test et:
ollama run llama3.1:8b
>>> Merhaba!  # TÃ¼rkÃ§e cevap gelmeli
>>> /bye      # Ã‡Ä±kmak iÃ§in
```

### 3ï¸âƒ£ Python Paketlerini GÃ¼ncelle

```bash
# Projenin ana dizininde:
pip install -r requirements.txt
```

### 4ï¸âƒ£ .env DosyasÄ± OluÅŸtur

```bash
# .env.local dosyasÄ±nÄ± kopyala
copy .env.local .env

# VEYA manuel oluÅŸtur ve ÅŸunu ekle:
LLM_PROVIDER=ollama
EMBEDDING_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b
EMBEDDING_MODEL=nomic-embed-text
```

### 5ï¸âƒ£ Test Et!

```bash
# Ollama kurulumunu test et
python test_ollama.py

# Her ÅŸey âœ… ise hazÄ±rsÄ±n!
```

### 6ï¸âƒ£ Vector Store OluÅŸtur

```bash
# Ä°lk kez Ã§alÄ±ÅŸtÄ±rÄ±yorsan vector store oluÅŸtur
python -c "from ingestion import initialize_vectorstore; initialize_vectorstore()"
```

### 7ï¸âƒ£ Ã‡alÄ±ÅŸtÄ±r! ğŸš€

```bash
# Ana uygulamayÄ± Ã§alÄ±ÅŸtÄ±r
python main.py

# VEYA CLI kullan
python cli.py interactive
```

---

## âœ… BaÅŸarÄ± KontrolÃ¼

EÄŸer ÅŸunlarÄ± gÃ¶rÃ¼yorsan her ÅŸey tamam:

```
âœ“ LLM connection test successful
âœ“ Embeddings connection test successful
âœ“ Vector store initialized successfully
```

---

## ğŸ› Sorun mu Var?

### "Ollama is not running"
```bash
# Ollama'yÄ± baÅŸlat
ollama serve

# VEYA Windows'ta gÃ¶rev Ã§ubuÄŸundan Ollama ikonunu ara
```

### "Model not found"
```bash
# Modelleri kontrol et
ollama list

# Yoksa indir
ollama pull llama3.1:8b
ollama pull nomic-embed-text
```

### "ImportError: langchain-community"
```bash
pip install langchain-community
```

---

## ğŸ“ DBS Entegrasyonu Ä°Ã§in Sonraki AdÄ±mlar

Sistem local'de Ã§alÄ±ÅŸtÄ±ktan sonra:

1. **Hocayla konuÅŸ**: DBS API dokÃ¼mantasyonu
2. **DBS Connector ekle**: `dbs_connector.py` oluÅŸtur
3. **Auto-sync ekle**: DokÃ¼manlarÄ± otomatik Ã§ek
4. **Test et**: GerÃ§ek ders dokÃ¼manlarÄ± ile
5. **Deploy**: Ãœniversite sunucusuna kur

---

## ğŸ’¡ Ä°puÃ§larÄ±

### Daha HÄ±zlÄ± Ã‡alÄ±ÅŸtÄ±rmak Ä°Ã§in:
```bash
# Daha kÃ¼Ã§Ã¼k model kullan
ollama pull llama3.2:3b

# .env'de gÃ¼ncelle:
OLLAMA_MODEL=llama3.2:3b
```

### Daha Ä°yi Kalite Ä°Ã§in:
```bash
# Daha bÃ¼yÃ¼k model (64GB RAM gerekir!)
ollama pull llama3.1:70b

# .env'de gÃ¼ncelle:
OLLAMA_MODEL=llama3.1:70b
```

### GPU KullanÄ±mÄ±:
Ollama otomatik olarak GPU kullanÄ±r (varsa). Kontrol iÃ§in:
```bash
nvidia-smi  # NVIDIA GPU varsa
```

---

## ğŸ“Š Maliyet KarÅŸÄ±laÅŸtÄ±rmasÄ±

| SeÃ§enek | AylÄ±k Maliyet | Kurulum | Performans |
|---------|---------------|---------|------------|
| **OpenAI API** | $30-100 | 5 dk | âš¡âš¡âš¡âš¡âš¡ |
| **Ollama Local** | **$0** ğŸ‰ | 15 dk | âš¡âš¡âš¡âš¡ |

**KazancÄ±nÄ±z**: $30-100/ay tasarruf! ğŸ’°

---

## ğŸ‰ BaÅŸarÄ±lÄ±!

ArtÄ±k tamamen Ã¼cretsiz, local bir RAG sisteminiz var!

**Sonraki adÄ±m**: `python cli.py interactive` ile soru sormaya baÅŸla! ğŸš€


